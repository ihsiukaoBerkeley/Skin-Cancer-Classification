{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CITglgXP2wiK"
   },
   "source": [
    "# Step 1: Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kES_rD67rrG6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xp6IRzqhu1Q9"
   },
   "source": [
    "# Step 2: Loading data and Making labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g7tDvsg5sNZK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dataset used: https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000\n",
    "image_path = \"archive/hmnist_28_28_RGB.csv\"\n",
    "meta_path = \"archive/HAM10000_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TSlPUvq-sfo4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(image_path)\n",
    "metadata = pd.read_csv(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-XZB67tXslAf",
    "outputId": "7ff89a09-b252-4e2b-82e9-282b328bc92e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>183</td>\n",
       "      <td>165</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>165</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>166</td>\n",
       "      <td>182</td>\n",
       "      <td>188</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>206</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>121</td>\n",
       "      <td>104</td>\n",
       "      <td>103</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>132</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>167</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>175</td>\n",
       "      <td>156</td>\n",
       "      <td>160</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>181</td>\n",
       "      <td>178</td>\n",
       "      <td>181</td>\n",
       "      <td>159</td>\n",
       "      <td>153</td>\n",
       "      <td>172</td>\n",
       "      <td>151</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>160</td>\n",
       "      <td>124</td>\n",
       "      <td>146</td>\n",
       "      <td>164</td>\n",
       "      <td>131</td>\n",
       "      <td>152</td>\n",
       "      <td>167</td>\n",
       "      <td>127</td>\n",
       "      <td>146</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>162</td>\n",
       "      <td>167</td>\n",
       "      <td>184</td>\n",
       "      <td>157</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>162</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>175</td>\n",
       "      <td>142</td>\n",
       "      <td>121</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>133</td>\n",
       "      <td>178</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "      <td>174</td>\n",
       "      <td>137</td>\n",
       "      <td>125</td>\n",
       "      <td>175</td>\n",
       "      <td>139</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "10010        183        165        181        182        165        180   \n",
       "10011          2          3          1         38         33         32   \n",
       "10012        132        118        118        167        149        149   \n",
       "10013        160        124        146        164        131        152   \n",
       "10014        175        142        121        181        150        134   \n",
       "\n",
       "       pixel0006  pixel0007  pixel0008  pixel0009  ...  pixel2343  pixel2344  \\\n",
       "10010        184        166        182        188  ...        208        185   \n",
       "10011        121        104        103        132  ...         96         79   \n",
       "10012        175        156        160        184  ...        204        181   \n",
       "10013        167        127        146        169  ...        185        162   \n",
       "10014        181        150        133        178  ...        159         79   \n",
       "\n",
       "       pixel2345  pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  \\\n",
       "10010        187        208        186        186        206        187   \n",
       "10011         76         24         23         21          3          4   \n",
       "10012        178        181        159        153        172        151   \n",
       "10013        167        184        157        166        185        162   \n",
       "10014         82        174        137        125        175        139   \n",
       "\n",
       "       pixel2351  label  \n",
       "10010        189      0  \n",
       "10011          1      0  \n",
       "10012        145      0  \n",
       "10013        172      0  \n",
       "10014        126      6  \n",
       "\n",
       "[5 rows x 2353 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033084</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033550</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033536</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>HAM_0000239</td>\n",
       "      <td>ISIC_0032854</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lesion_id      image_id     dx dx_type   age     sex localization\n",
       "10010  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male      abdomen\n",
       "10011  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male      abdomen\n",
       "10012  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male      abdomen\n",
       "10013  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male         face\n",
       "10014  HAM_0003521  ISIC_0032258    mel   histo  70.0  female         back"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>183</td>\n",
       "      <td>165</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>165</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>206</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>132</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>167</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>181</td>\n",
       "      <td>178</td>\n",
       "      <td>181</td>\n",
       "      <td>159</td>\n",
       "      <td>153</td>\n",
       "      <td>172</td>\n",
       "      <td>151</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>160</td>\n",
       "      <td>124</td>\n",
       "      <td>146</td>\n",
       "      <td>164</td>\n",
       "      <td>131</td>\n",
       "      <td>152</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>162</td>\n",
       "      <td>167</td>\n",
       "      <td>184</td>\n",
       "      <td>157</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>162</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>175</td>\n",
       "      <td>142</td>\n",
       "      <td>121</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "      <td>174</td>\n",
       "      <td>137</td>\n",
       "      <td>125</td>\n",
       "      <td>175</td>\n",
       "      <td>139</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age     sex localization  pixel0000  pixel0001  pixel0002  pixel0003  \\\n",
       "10010  40.0    male      abdomen        183        165        181        182   \n",
       "10011  40.0    male      abdomen          2          3          1         38   \n",
       "10012  40.0    male      abdomen        132        118        118        167   \n",
       "10013  80.0    male         face        160        124        146        164   \n",
       "10014  70.0  female         back        175        142        121        181   \n",
       "\n",
       "       pixel0004  pixel0005  pixel0006  ...  pixel2343  pixel2344  pixel2345  \\\n",
       "10010        165        180        184  ...        208        185        187   \n",
       "10011         33         32        121  ...         96         79         76   \n",
       "10012        149        149        175  ...        204        181        178   \n",
       "10013        131        152        167  ...        185        162        167   \n",
       "10014        150        134        181  ...        159         79         82   \n",
       "\n",
       "       pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  pixel2351  label  \n",
       "10010        208        186        186        206        187        189      0  \n",
       "10011         24         23         21          3          4          1      0  \n",
       "10012        181        159        153        172        151        145      0  \n",
       "10013        184        157        166        185        162        172      0  \n",
       "10014        174        137        125        175        139        126      6  \n",
       "\n",
       "[5 rows x 2356 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop NA values\n",
    "meta_set = metadata[[\"age\", \"sex\", \"localization\"]]\n",
    "df = pd.concat([meta_set, df], axis = 1)\n",
    "df = df.dropna()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4Cw9UFa1rsr"
   },
   "source": [
    "# Step 3: Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split counts (train/ validation/ test): [5974 1991 1991]\n"
     ]
    }
   ],
   "source": [
    "# Split into train, validation, and test.\n",
    "np.random.seed(2070404)\n",
    "\n",
    "# Shuffle all records.\n",
    "df_shuffle = df.sample(frac = 1)\n",
    "\n",
    "# Create split counts.\n",
    "splits = np.multiply(len(df_shuffle), (0.6,0.2,0.2)).astype(int)\n",
    "print(f\"Split counts (train/ validation/ test): {splits}\")\n",
    "\n",
    "# Create split data sets.\n",
    "train_set, valid_set, test_set = np.split(df_shuffle, [splits[0], splits[0] + splits[1]])\n",
    "\n",
    "# Reset split set indicies.\n",
    "train_set.reset_index(drop = True, inplace = True)\n",
    "valid_set.reset_index(drop = True, inplace = True)\n",
    "test_set.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2W5sBRkZtBr9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#separate features and labels\n",
    "y_train_clean = train_set['label']\n",
    "x_train_clean = train_set.drop(columns=['label'])\n",
    "\n",
    "y_valid = valid_set['label']\n",
    "x_valid = valid_set.drop(columns=['label'])\n",
    "\n",
    "y_test = test_set['label']\n",
    "x_test = test_set.drop(columns=['label'])\n",
    "\n",
    "columns = list(x_train_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5i_16okiu1Rf"
   },
   "source": [
    "# Step 4: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following labels are malignant\n",
    "label 0: AKIEC (Actinic Keratoses and Intraepithelial Carcinoma)\n",
    "label 1: BCC (Basal Cell Carcinoma)\n",
    "label 6: MEL (Melanoma)\n",
    "\"\"\"\n",
    "\n",
    "def classify_label_malignant(df_row):\n",
    "    \"\"\" \n",
    "    return whether a record is malignant\n",
    "    \n",
    "    Args:\n",
    "    df_row: single record\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    1.0 if malignant\n",
    "    0.0 if not malignant\n",
    "    \"\"\"\n",
    "    \n",
    "    if df_row == 0 or df_row == 1 or df_row == 6:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5969    1.0\n",
       "5970    0.0\n",
       "5971    0.0\n",
       "5972    1.0\n",
       "5973    0.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply classify_label_malignant to train, validation, and test set label to gain binary classification of whether a record is malignant\n",
    "\n",
    "\n",
    "y_train_clean = y_train_clean.apply(classify_label_malignant)\n",
    "y_valid = y_valid.apply(classify_label_malignant)\n",
    "y_test = y_test.apply(classify_label_malignant)\n",
    "\n",
    "y_train_clean.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "#create a new train set that over-sample the minority class(es) by picking samples at random with replacement\n",
    "oversample = RandomOverSampler()\n",
    "x_train_oversample, y_train_oversample  = oversample.fit_resample(x_train_clean, y_train_clean)\n",
    "\n",
    "#create encoder to encode categorical features as one-hot arrays\n",
    "ohe = OneHotEncoder()\n",
    "#create scaler to standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#apply encoder and scaler on clean (original) dataset's metadata\n",
    "categorical_data_clean = ohe.fit_transform(x_train_clean[['sex', 'localization']]).toarray()\n",
    "numerical_data_clean = scaler.fit_transform(x_train_clean[['age']].values)\n",
    "train_tabular_clean = np.concatenate([categorical_data_clean, numerical_data_clean], axis = 1)\n",
    "x_train_clean = x_train_clean.iloc[:,3:]\n",
    "\n",
    "#apply encoder and scaler on oversample dataset's metadata\n",
    "categorical_data_oversample = ohe.transform(x_train_oversample[['sex', 'localization']]).toarray()\n",
    "numerical_data_oversample = scaler.transform(x_train_oversample[['age']].values)\n",
    "train_tabular_oversample = np.concatenate([categorical_data_oversample, numerical_data_oversample], axis = 1)\n",
    "x_train_oversample = x_train_oversample.iloc[:,3:]\n",
    "\n",
    "#apply encoder and scaler on validation dataset's metadata\n",
    "categorical_data_valid = ohe.transform(x_valid[['sex', 'localization']]).toarray()\n",
    "numerical_data_valid = scaler.transform(x_valid[['age']].values)\n",
    "valid_tabular_set = np.concatenate([categorical_data_valid, numerical_data_valid], axis = 1)\n",
    "x_valid = x_valid.iloc[:,3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5974, 19)\n",
      "(5974, 2352)\n"
     ]
    }
   ],
   "source": [
    "print(train_tabular_clean.shape)\n",
    "print(x_train_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9636, 19)\n",
      "(9636, 2352)\n"
     ]
    }
   ],
   "source": [
    "print(train_tabular_oversample.shape)\n",
    "print(x_train_oversample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1991, 19)\n",
      "(1991, 2352)\n"
     ]
    }
   ],
   "source": [
    "print(valid_tabular_set.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "84ADzEUx5R9I",
    "outputId": "052655c5-cf03-45b5-d7f7-eb8e2e41637a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "x_train_clean = np.array(x_train_clean, dtype=np.uint8).reshape(-1,28,28,3)\n",
    "x_train_oversample = np.array(x_train_oversample, dtype=np.uint8).reshape(-1,28,28,3)\n",
    "x_valid = np.array(x_valid, dtype=np.uint8).reshape(-1,28,28,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "obmDZia7Sxnn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_augm = x_valid / 255.0\n",
    "\n",
    "def aug_image(x_train_set, tabular_set, y_train_set, contrast_factor = 2, delta = 0.1, flip_flag = True):\n",
    "    \"\"\" \n",
    "    apply transformaions and augmentations\n",
    "    \n",
    "    Args:\n",
    "    x_train_set: dataset to be augmented and transformed\n",
    "    tabular_set: metadata of the dataset\n",
    "    y_train_set: labels of the dataset\n",
    "    contrast_factor: contrast factor to be used\n",
    "    delta: delta value to be used\n",
    "    flip_flag: whether to apply flipping transformation to the dataset\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    x_train_set_augm: transformed and augmented dataset\n",
    "    tabular_set_augm: metadata of the transformed and augmented dataset\n",
    "    y_train_set_augm: labels of the transformed and augmented dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    tf.random.set_seed(1234)\n",
    "\n",
    "    #transform image to greyscale\n",
    "    x_train_set_augm = x_train_set / 255.0\n",
    "\n",
    "    #change delta\n",
    "    x_train_set_augm = tf.image.adjust_brightness(x_train_set_augm, delta = delta)\n",
    "\n",
    "    #change contrast\n",
    "    x_train_set_augm = tf.image.adjust_contrast(x_train_set_augm, contrast_factor = contrast_factor)\n",
    "\n",
    "    #flip image\n",
    "    if flip_flag:\n",
    "        x_train_set_augm = tf.image.random_flip_left_right(x_train_set_augm)\n",
    "\n",
    "    #concatenate original dataset and augmented dataset\n",
    "    x_train_set_augm = tf.concat([x_train_set, x_train_set_augm], axis = 0)\n",
    "    \n",
    "    #concatenate original dataset metadata with itselt\n",
    "    tabular_set_augm = tabular_set\n",
    "    tabular_set_augm = tf.concat([tabular_set_augm, tabular_set], axis = 0)\n",
    "\n",
    "    #concatenate original dataset labels with itselt\n",
    "    y_train_set_augm = y_train_set\n",
    "    y_train_set_augm = tf.concat([y_train_set, y_train_set_augm], axis = 0)\n",
    "\n",
    "\n",
    "    #shuffle dataset\n",
    "    shuffle = tf.random.shuffle(tf.range(tf.shape(x_train_set_augm)[0], dtype = tf.int32))\n",
    "    x_train_set_augm = tf.gather(x_train_set_augm, shuffle)\n",
    "    tabular_set_augm = tf.gather(tabular_set_augm, shuffle)\n",
    "    y_train_set_augm = tf.gather(y_train_set_augm, shuffle).numpy() #also transforms y_train to numpy array\n",
    "\n",
    "    #print(x_train_set_augm.shape)\n",
    "    \n",
    "    return x_train_set_augm, tabular_set_augm, y_train_set_augm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQlw_baKxPQw"
   },
   "source": [
    "# Step 5: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: build a neural network model for metadata features (tabular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tabular_model(input_dim = 19, activation_func = \"relu\", tabular_dense_list = [64]):    \n",
    "    \"\"\" \n",
    "    build a neural network model using keras\n",
    "    \n",
    "    Args:\n",
    "    input_dim: dimension of the input\n",
    "    activation_func: activation function to be used in the hidden dense layers\n",
    "    tabular_dense_list: a list of dense layer units to be added\n",
    "    \n",
    "    Returns:\n",
    "    model: A tf.keras model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    for i in range(len(tabular_dense_list)):\n",
    "        #add dense layer 1\n",
    "        if i == 0:\n",
    "            model.add(tf.keras.layers.Dense(\n",
    "                units = tabular_dense_list[i],\n",
    "                activation = activation_func,\n",
    "                input_dim = input_dim))\n",
    "        #add additional dense layer(s)\n",
    "        else:\n",
    "            model.add(tf.keras.layers.Dense(\n",
    "                units = tabular_dense_list[i],\n",
    "                activation = activation_func))\n",
    "            \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: build a CNN model for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Vsll2hd2wzuS",
    "outputId": "72d98919-77a3-46eb-ea1d-fecce118efcb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_cnn_model(kernel_size = 2, pool_size = 2):\n",
    "    \"\"\"\n",
    "    Build a CNN model using Keras.\n",
    "\n",
    "    Args:\n",
    "    kernel_size: convolution layer kernel size\n",
    "    pool_size: pooling layer pool size\n",
    "\n",
    "    Returns:\n",
    "    model: A tf.keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    #add convolution layer 1\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters = 32, kernel_size = (kernel_size, kernel_size),\n",
    "        strides=(1,1), padding='same',\n",
    "        data_format = 'channels_last',\n",
    "        input_shape = (28, 28, 3),  # Updated input shape for RGB\n",
    "        name='conv_1', activation='relu'))\n",
    "\n",
    "    #add pooling layer 1\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size = (pool_size, pool_size), name = 'pool_1'))\n",
    "\n",
    "    #add convolution layer 2\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters = 64, kernel_size = (kernel_size, kernel_size),\n",
    "        strides = (1,1), padding = 'same',\n",
    "        name = 'conv_2', activation = 'relu'))\n",
    "\n",
    "    #add pooling layer 2\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size = (pool_size, pool_size), name = 'pool_2'))\n",
    "\n",
    "    #add flattening layer\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "\n",
    "    #add dense layer 1\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units = 1024, name = 'fc_1', \n",
    "        activation = 'relu'))\n",
    "\n",
    "    #dropout\n",
    "    model.add(tf.keras.layers.Dropout(rate = 0.5))\n",
    "    \n",
    "    #add dense layer 2\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units = 1024, name = 'dense2', \n",
    "        activation = 'relu'))\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3: build a mixed model combining the neural network for tabular data and the CNN for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mixed_model(kernel_size = 2, pool_size = 2, tabular_shape = 19, tabular_activation_func = \"relu\", tabular_dense_list = [64], mixed_dense_list = [1024]):\n",
    "    \"\"\"\n",
    "    Build a mixed model using Keras.\n",
    "\n",
    "    Args:\n",
    "    kernel_size: convolution layer kernel size\n",
    "    pool_size: pooling layer pool size\n",
    "    tabular_shape: dimension of the input\n",
    "    tabular_activation_func: activation function to be used in the hidden dense layers\n",
    "    tabular_dense_list: a list of dense layer units to be added to the tabular NN model\n",
    "    mixed_dense_list: a list of dense layer units to be added to the mixed model\n",
    "\n",
    "    Returns:\n",
    "    model: A tf.keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    #clear previous sessions\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    #initialize two models\n",
    "    cnn_model = build_cnn_model(kernel_size = kernel_size, pool_size = pool_size)\n",
    "    tabular_model = build_tabular_model(input_dim = tabular_shape, activation_func = tabular_activation_func, tabular_dense_list = tabular_dense_list)\n",
    "\n",
    "    #concatenate the two models by adding a concatenation layer\n",
    "    combined_input = tf.keras.layers.concatenate([cnn_model.output, tabular_model.output])\n",
    "    \n",
    "    curr_layer = combined_input\n",
    "\n",
    "    #add more dense layers based on dense_list\n",
    "    for i in mixed_dense_list:\n",
    "        curr_layer = tf.keras.layers.Dense(i, activation = 'relu')(curr_layer)\n",
    "    \n",
    "    #add output layer\n",
    "    output = tf.keras.layers.Dense(1, activation = 'sigmoid')(curr_layer) \n",
    "\n",
    "    model = tf.keras.Model(inputs = [cnn_model.input, tabular_model.input], outputs = output)\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), \n",
    "                  loss = 'binary_crossentropy',  \n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Fitting the Model Using Different Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of dense layer unit lists for mixed model\n",
    "mixed_dense_lists = [[1024], [1024, 512], [1024, 512, 256], [1024, 512, 256, 128], [1024, 512, 256, 128, 64], [1024, 512, 256, 128, 64, 32]]\n",
    "\n",
    "#chose the tabular dense list that performed the best in previous testing\n",
    "tabular_dense_lists = [[32, 64, 64]]\n",
    "\n",
    "#chose the tabular activation function that peformed the \n",
    "activation_list = [\"tanh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1: fit models using clean (original) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---mixed dense list: [1024], tabular dense list: [32, 64, 64], activation: tanh---\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 2s 30ms/step - loss: 7.5144 - accuracy: 0.7466 - val_loss: 0.3760 - val_accuracy: 0.8036\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3827 - accuracy: 0.8026 - val_loss: 0.3519 - val_accuracy: 0.8147\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3685 - accuracy: 0.8120 - val_loss: 0.3934 - val_accuracy: 0.8132\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3637 - accuracy: 0.8124 - val_loss: 0.3294 - val_accuracy: 0.8312\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.3689 - accuracy: 0.8206 - val_loss: 0.3354 - val_accuracy: 0.8182\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.3544 - accuracy: 0.8231 - val_loss: 0.3328 - val_accuracy: 0.8247\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.3479 - accuracy: 0.8266 - val_loss: 0.3259 - val_accuracy: 0.8307\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.3493 - accuracy: 0.8257 - val_loss: 0.3284 - val_accuracy: 0.8398\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.3369 - accuracy: 0.8329 - val_loss: 0.3292 - val_accuracy: 0.8338\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.3476 - accuracy: 0.8338 - val_loss: 0.3264 - val_accuracy: 0.8332\n",
      "---mixed dense list: [1024, 512], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 2s 31ms/step - loss: 4.1191 - accuracy: 0.7578 - val_loss: 0.3980 - val_accuracy: 0.8076\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3777 - accuracy: 0.8040 - val_loss: 0.3378 - val_accuracy: 0.8227\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3761 - accuracy: 0.8102 - val_loss: 0.3557 - val_accuracy: 0.8232\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.3682 - accuracy: 0.8164 - val_loss: 0.3420 - val_accuracy: 0.8227\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3526 - accuracy: 0.8139 - val_loss: 0.3267 - val_accuracy: 0.8307\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.3475 - accuracy: 0.8219 - val_loss: 0.3313 - val_accuracy: 0.8287\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3536 - accuracy: 0.8224 - val_loss: 0.3251 - val_accuracy: 0.8272\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3445 - accuracy: 0.8259 - val_loss: 0.3322 - val_accuracy: 0.8267\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3378 - accuracy: 0.8308 - val_loss: 0.3236 - val_accuracy: 0.8383\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3414 - accuracy: 0.8299 - val_loss: 0.3295 - val_accuracy: 0.8338\n",
      "---mixed dense list: [1024, 512, 256], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 2s 30ms/step - loss: 2.5298 - accuracy: 0.7794 - val_loss: 0.3684 - val_accuracy: 0.8152\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3668 - accuracy: 0.8080 - val_loss: 0.3381 - val_accuracy: 0.8257\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3607 - accuracy: 0.8135 - val_loss: 0.3453 - val_accuracy: 0.8122\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.3650 - accuracy: 0.8107 - val_loss: 0.3330 - val_accuracy: 0.8237\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3509 - accuracy: 0.8211 - val_loss: 0.3385 - val_accuracy: 0.8252\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.3483 - accuracy: 0.8278 - val_loss: 0.3318 - val_accuracy: 0.8247\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3419 - accuracy: 0.8278 - val_loss: 0.3220 - val_accuracy: 0.8398\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.3370 - accuracy: 0.8303 - val_loss: 0.3472 - val_accuracy: 0.8292\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3577 - accuracy: 0.8154 - val_loss: 0.3313 - val_accuracy: 0.8252\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.3395 - accuracy: 0.8286 - val_loss: 0.3358 - val_accuracy: 0.8217\n",
      "---mixed dense list: [1024, 512, 256, 128], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 2s 30ms/step - loss: 1.1703 - accuracy: 0.7804 - val_loss: 0.3714 - val_accuracy: 0.8167\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.3783 - accuracy: 0.8016 - val_loss: 0.3509 - val_accuracy: 0.8056\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3574 - accuracy: 0.8132 - val_loss: 0.3960 - val_accuracy: 0.7956\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3591 - accuracy: 0.8060 - val_loss: 0.3365 - val_accuracy: 0.8247\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3533 - accuracy: 0.8206 - val_loss: 0.3299 - val_accuracy: 0.8272\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3448 - accuracy: 0.8244 - val_loss: 0.3293 - val_accuracy: 0.8332\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3484 - accuracy: 0.8286 - val_loss: 0.3284 - val_accuracy: 0.8307\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3442 - accuracy: 0.8271 - val_loss: 0.3283 - val_accuracy: 0.8348\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3406 - accuracy: 0.8273 - val_loss: 0.3493 - val_accuracy: 0.8277\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3387 - accuracy: 0.8304 - val_loss: 0.3173 - val_accuracy: 0.8343\n",
      "---mixed dense list: [1024, 512, 256, 128, 64], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 2s 31ms/step - loss: 1.4605 - accuracy: 0.7651 - val_loss: 0.4008 - val_accuracy: 0.8056\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3780 - accuracy: 0.8068 - val_loss: 0.3500 - val_accuracy: 0.8177\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3614 - accuracy: 0.8139 - val_loss: 0.3489 - val_accuracy: 0.8177\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3725 - accuracy: 0.8102 - val_loss: 0.3688 - val_accuracy: 0.8302\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3526 - accuracy: 0.8217 - val_loss: 0.3285 - val_accuracy: 0.8312\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3442 - accuracy: 0.8229 - val_loss: 0.3317 - val_accuracy: 0.8312\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3485 - accuracy: 0.8237 - val_loss: 0.3438 - val_accuracy: 0.8302\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.3466 - accuracy: 0.8286 - val_loss: 0.3255 - val_accuracy: 0.8413\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3385 - accuracy: 0.8313 - val_loss: 0.3159 - val_accuracy: 0.8418\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3338 - accuracy: 0.8361 - val_loss: 0.3264 - val_accuracy: 0.8343\n",
      "---mixed dense list: [1024, 512, 256, 128, 64, 32], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 2s 30ms/step - loss: 1.0353 - accuracy: 0.7678 - val_loss: 0.3616 - val_accuracy: 0.8056\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3662 - accuracy: 0.8097 - val_loss: 0.3762 - val_accuracy: 0.8026\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3573 - accuracy: 0.8149 - val_loss: 0.3549 - val_accuracy: 0.8247\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3593 - accuracy: 0.8214 - val_loss: 0.3319 - val_accuracy: 0.8302\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.3460 - accuracy: 0.8252 - val_loss: 0.3393 - val_accuracy: 0.8242\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3422 - accuracy: 0.8273 - val_loss: 0.3434 - val_accuracy: 0.8227\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.3379 - accuracy: 0.8323 - val_loss: 0.3389 - val_accuracy: 0.8112\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3472 - accuracy: 0.8251 - val_loss: 0.3520 - val_accuracy: 0.8242\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.3427 - accuracy: 0.8309 - val_loss: 0.3253 - val_accuracy: 0.8348\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.3312 - accuracy: 0.8366 - val_loss: 0.3338 - val_accuracy: 0.8388\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clean_dict = {}\n",
    "\n",
    "for mixed_dense_list in mixed_dense_lists:\n",
    "    for tabular_dense_list in tabular_dense_lists:\n",
    "        for activation_func in activation_list:\n",
    "        \n",
    "            print(\"---mixed dense list: \" + str(mixed_dense_list) + \", tabular dense list: \" + str(tabular_dense_list) + \", activation: \" + activation_func + \"---\")\n",
    "    \n",
    "            model = build_mixed_model(kernel_size = 3,\n",
    "                                      pool_size = 3,\n",
    "                                      tabular_shape = train_tabular_clean.shape[1],\n",
    "                                      tabular_activation_func = activation_func,\n",
    "                                      tabular_dense_list = tabular_dense_list,\n",
    "                                      mixed_dense_list = mixed_dense_list)\n",
    "    \n",
    "            history = model.fit(\n",
    "                [x_train_clean,\n",
    "                 train_tabular_clean],\n",
    "                y_train_clean,\n",
    "                validation_data = ([x_valid,\n",
    "                                    valid_tabular_set],\n",
    "                                   y_valid),\n",
    "                epochs = 10,  \n",
    "                batch_size = 128\n",
    "            )\n",
    "    \n",
    "            clean_dict[(len(mixed_dense_list), len(tabular_dense_list), activation_func)] = [history.history['accuracy'][-1], history.history['val_accuracy'][-1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2: fit models using oversample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---mixed dense list: [1024], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "76/76 [==============================] - 2s 25ms/step - loss: 7.1060 - accuracy: 0.6594 - val_loss: 0.4911 - val_accuracy: 0.7499\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 2s 24ms/step - loss: 0.4894 - accuracy: 0.7631 - val_loss: 0.3988 - val_accuracy: 0.7810\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 2s 25ms/step - loss: 0.4668 - accuracy: 0.7764 - val_loss: 0.3810 - val_accuracy: 0.7760\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 2s 25ms/step - loss: 0.4551 - accuracy: 0.7828 - val_loss: 0.3870 - val_accuracy: 0.7735\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 2s 25ms/step - loss: 0.4422 - accuracy: 0.7832 - val_loss: 0.4767 - val_accuracy: 0.7268\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 2s 24ms/step - loss: 0.4295 - accuracy: 0.7922 - val_loss: 0.4204 - val_accuracy: 0.7534\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 2s 25ms/step - loss: 0.4281 - accuracy: 0.7949 - val_loss: 0.3883 - val_accuracy: 0.7700\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 2s 25ms/step - loss: 0.4089 - accuracy: 0.8034 - val_loss: 0.3840 - val_accuracy: 0.7765\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 2s 25ms/step - loss: 0.3967 - accuracy: 0.8113 - val_loss: 0.4023 - val_accuracy: 0.7634\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 2s 25ms/step - loss: 0.3936 - accuracy: 0.8106 - val_loss: 0.4124 - val_accuracy: 0.7579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---mixed dense list: [1024, 512], tabular dense list: [32, 64, 64], activation: tanh---\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 2s 26ms/step - loss: 4.2251 - accuracy: 0.6503 - val_loss: 0.4460 - val_accuracy: 0.7534\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 2s 26ms/step - loss: 0.4703 - accuracy: 0.7727 - val_loss: 0.3833 - val_accuracy: 0.7740\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 2s 25ms/step - loss: 0.4502 - accuracy: 0.7845 - val_loss: 0.4256 - val_accuracy: 0.7398\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 2s 27ms/step - loss: 0.4330 - accuracy: 0.7921 - val_loss: 0.4067 - val_accuracy: 0.7685\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.4267 - accuracy: 0.7988 - val_loss: 0.4159 - val_accuracy: 0.7514\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 2s 27ms/step - loss: 0.4188 - accuracy: 0.8022 - val_loss: 0.3809 - val_accuracy: 0.7850\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 2s 26ms/step - loss: 0.4169 - accuracy: 0.8022 - val_loss: 0.4342 - val_accuracy: 0.7539\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 2s 26ms/step - loss: 0.4056 - accuracy: 0.8097 - val_loss: 0.3955 - val_accuracy: 0.7820\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 2s 26ms/step - loss: 0.3827 - accuracy: 0.8186 - val_loss: 0.4370 - val_accuracy: 0.7770\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 2s 26ms/step - loss: 0.3672 - accuracy: 0.8301 - val_loss: 0.3374 - val_accuracy: 0.8187\n",
      "---mixed dense list: [1024, 512, 256], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 2.3963 - accuracy: 0.6650 - val_loss: 0.4270 - val_accuracy: 0.7564\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 2s 27ms/step - loss: 0.4716 - accuracy: 0.7727 - val_loss: 0.5469 - val_accuracy: 0.6936\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4606 - val_accuracy: 0.7308\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.4366 - accuracy: 0.7913 - val_loss: 0.4375 - val_accuracy: 0.7353\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.4392 - accuracy: 0.7897 - val_loss: 0.4030 - val_accuracy: 0.7519\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4154 - accuracy: 0.8016 - val_loss: 0.3702 - val_accuracy: 0.7896\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4029 - accuracy: 0.8073 - val_loss: 0.3343 - val_accuracy: 0.8192\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3928 - accuracy: 0.8140 - val_loss: 0.3930 - val_accuracy: 0.7484\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3856 - accuracy: 0.8198 - val_loss: 0.4033 - val_accuracy: 0.7519\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3639 - accuracy: 0.8298 - val_loss: 0.3865 - val_accuracy: 0.7639\n",
      "---mixed dense list: [1024, 512, 256, 128], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "76/76 [==============================] - 3s 31ms/step - loss: 1.2096 - accuracy: 0.6800 - val_loss: 0.4150 - val_accuracy: 0.7760\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4671 - accuracy: 0.7760 - val_loss: 0.4832 - val_accuracy: 0.7238\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4558 - accuracy: 0.7839 - val_loss: 0.6117 - val_accuracy: 0.6514\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4438 - accuracy: 0.7867 - val_loss: 0.4065 - val_accuracy: 0.7519\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 0.4382 - accuracy: 0.7913 - val_loss: 0.4641 - val_accuracy: 0.7273\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.4188 - accuracy: 0.7978 - val_loss: 0.4360 - val_accuracy: 0.7534\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.4152 - accuracy: 0.8005 - val_loss: 0.4115 - val_accuracy: 0.7378\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 0.4028 - accuracy: 0.8076 - val_loss: 0.4141 - val_accuracy: 0.7760\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 0.3920 - accuracy: 0.8149 - val_loss: 0.4107 - val_accuracy: 0.7750\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3734 - accuracy: 0.8270 - val_loss: 0.4909 - val_accuracy: 0.7233\n",
      "---mixed dense list: [1024, 512, 256, 128, 64], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 1.1768 - accuracy: 0.6777 - val_loss: 0.4036 - val_accuracy: 0.7670\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.4729 - accuracy: 0.7712 - val_loss: 0.3887 - val_accuracy: 0.7750\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4600 - accuracy: 0.7765 - val_loss: 0.4042 - val_accuracy: 0.7569\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4527 - accuracy: 0.7811 - val_loss: 0.4209 - val_accuracy: 0.7574\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 0.4427 - accuracy: 0.7893 - val_loss: 0.4641 - val_accuracy: 0.7338\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.4264 - accuracy: 0.7959 - val_loss: 0.5114 - val_accuracy: 0.7258\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.4338 - accuracy: 0.7907 - val_loss: 0.3831 - val_accuracy: 0.7936\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 0.4138 - accuracy: 0.8005 - val_loss: 0.4301 - val_accuracy: 0.7469\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.4022 - accuracy: 0.8078 - val_loss: 0.4665 - val_accuracy: 0.7278\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 0.3931 - accuracy: 0.8120 - val_loss: 0.4316 - val_accuracy: 0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---mixed dense list: [1024, 512, 256, 128, 64, 32], tabular dense list: [32, 64, 64], activation: tanh---\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 0.8470 - accuracy: 0.6549 - val_loss: 0.4163 - val_accuracy: 0.7649\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.4832 - accuracy: 0.7700 - val_loss: 0.4916 - val_accuracy: 0.7037\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 2s 27ms/step - loss: 0.4546 - accuracy: 0.7780 - val_loss: 0.3975 - val_accuracy: 0.7524\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 2s 27ms/step - loss: 0.4363 - accuracy: 0.7914 - val_loss: 0.3811 - val_accuracy: 0.7639\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.4291 - accuracy: 0.7930 - val_loss: 0.3865 - val_accuracy: 0.7820\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.4122 - accuracy: 0.8039 - val_loss: 0.4598 - val_accuracy: 0.7338\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.4009 - accuracy: 0.8086 - val_loss: 0.3738 - val_accuracy: 0.8147\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 0.3800 - accuracy: 0.8206 - val_loss: 0.3593 - val_accuracy: 0.8081\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 2s 28ms/step - loss: 0.3622 - accuracy: 0.8309 - val_loss: 0.4011 - val_accuracy: 0.7800\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 2s 29ms/step - loss: 0.3524 - accuracy: 0.8347 - val_loss: 0.4457 - val_accuracy: 0.7353\n"
     ]
    }
   ],
   "source": [
    "\n",
    "oversample_dict = {}\n",
    "\n",
    "for mixed_dense_list in mixed_dense_lists:\n",
    "    for tabular_dense_list in tabular_dense_lists:\n",
    "        for activation_func in activation_list:\n",
    "        \n",
    "            print(\"---mixed dense list: \" + str(mixed_dense_list) + \", tabular dense list: \" + str(tabular_dense_list) + \", activation: \" + activation_func + \"---\")\n",
    "    \n",
    "            model = build_mixed_model(kernel_size = 3,\n",
    "                                      pool_size = 3,\n",
    "                                      tabular_shape = train_tabular_oversample.shape[1],\n",
    "                                      tabular_activation_func = activation_func,\n",
    "                                      tabular_dense_list = tabular_dense_list,\n",
    "                                      mixed_dense_list = mixed_dense_list)\n",
    "    \n",
    "            history = model.fit(\n",
    "                [x_train_oversample,\n",
    "                 train_tabular_oversample],\n",
    "                y_train_oversample,\n",
    "                validation_data = ([x_valid,\n",
    "                                    valid_tabular_set],\n",
    "                                   y_valid),\n",
    "                epochs=10,  \n",
    "                batch_size=128\n",
    "            )\n",
    "\n",
    "            oversample_dict[(len(mixed_dense_list), len(tabular_dense_list), activation_func)] = [history.history['accuracy'][-1], history.history['val_accuracy'][-1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3: fit models using image augmentation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---mixed dense list: [1024], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 3s 25ms/step - loss: 1.2147 - accuracy: 0.7903 - val_loss: 0.3944 - val_accuracy: 0.8071\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.3927 - accuracy: 0.8057 - val_loss: 0.3856 - val_accuracy: 0.8056\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.3888 - accuracy: 0.8076 - val_loss: 0.3525 - val_accuracy: 0.8187\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.3702 - accuracy: 0.8100 - val_loss: 0.3613 - val_accuracy: 0.8142\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.3652 - accuracy: 0.8104 - val_loss: 0.3636 - val_accuracy: 0.8127\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.3583 - accuracy: 0.8140 - val_loss: 0.3621 - val_accuracy: 0.8197\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.3587 - accuracy: 0.8165 - val_loss: 0.3434 - val_accuracy: 0.8152\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.3596 - accuracy: 0.8154 - val_loss: 0.3402 - val_accuracy: 0.8237\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.3991 - accuracy: 0.8106 - val_loss: 0.3367 - val_accuracy: 0.8177\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.3523 - accuracy: 0.8164 - val_loss: 0.3316 - val_accuracy: 0.8162\n",
      "---mixed dense list: [1024, 512], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 3s 27ms/step - loss: 0.9511 - accuracy: 0.7944 - val_loss: 0.3925 - val_accuracy: 0.8122\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.3887 - accuracy: 0.8022 - val_loss: 0.4038 - val_accuracy: 0.8142\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3951 - accuracy: 0.8029 - val_loss: 0.3576 - val_accuracy: 0.8056\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3731 - accuracy: 0.8076 - val_loss: 0.3523 - val_accuracy: 0.8137\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.3772 - accuracy: 0.8065 - val_loss: 0.3407 - val_accuracy: 0.8086\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 3s 27ms/step - loss: 0.3693 - accuracy: 0.8094 - val_loss: 0.3421 - val_accuracy: 0.8086\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.3606 - accuracy: 0.8135 - val_loss: 0.3358 - val_accuracy: 0.8066\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 3s 27ms/step - loss: 0.3672 - accuracy: 0.8095 - val_loss: 0.4042 - val_accuracy: 0.8147\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.3591 - accuracy: 0.8144 - val_loss: 0.3394 - val_accuracy: 0.8112\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 3s 27ms/step - loss: 0.3614 - accuracy: 0.8155 - val_loss: 0.3363 - val_accuracy: 0.8071\n",
      "---mixed dense list: [1024, 512, 256], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 1.2059 - accuracy: 0.7891 - val_loss: 0.3963 - val_accuracy: 0.8076\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.3962 - accuracy: 0.8058 - val_loss: 0.3945 - val_accuracy: 0.8056\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3905 - accuracy: 0.8031 - val_loss: 0.3731 - val_accuracy: 0.8041\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 3s 27ms/step - loss: 0.3869 - accuracy: 0.8052 - val_loss: 0.3590 - val_accuracy: 0.8202\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3690 - accuracy: 0.8082 - val_loss: 0.3413 - val_accuracy: 0.8061\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.3845 - accuracy: 0.8063 - val_loss: 0.3993 - val_accuracy: 0.8086\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.3992 - accuracy: 0.8066 - val_loss: 0.3772 - val_accuracy: 0.8056\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3721 - accuracy: 0.8065 - val_loss: 0.3465 - val_accuracy: 0.8192\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3635 - accuracy: 0.8105 - val_loss: 0.3427 - val_accuracy: 0.8157\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3597 - accuracy: 0.8130 - val_loss: 0.3383 - val_accuracy: 0.8081\n",
      "---mixed dense list: [1024, 512, 256, 128], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.7991 - accuracy: 0.7947 - val_loss: 0.3982 - val_accuracy: 0.8056\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3875 - accuracy: 0.8062 - val_loss: 0.3665 - val_accuracy: 0.8056\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.3962 - accuracy: 0.8062 - val_loss: 0.3645 - val_accuracy: 0.8056\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.3700 - accuracy: 0.8101 - val_loss: 0.3546 - val_accuracy: 0.8096\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3692 - accuracy: 0.8108 - val_loss: 0.3629 - val_accuracy: 0.8051\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3641 - accuracy: 0.8091 - val_loss: 0.3461 - val_accuracy: 0.8101\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3569 - accuracy: 0.8129 - val_loss: 0.3309 - val_accuracy: 0.8091\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3542 - accuracy: 0.8144 - val_loss: 0.3332 - val_accuracy: 0.8192\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3478 - accuracy: 0.8197 - val_loss: 0.3444 - val_accuracy: 0.8182\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.3723 - accuracy: 0.8124 - val_loss: 0.3391 - val_accuracy: 0.8132\n",
      "---mixed dense list: [1024, 512, 256, 128, 64], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.7088 - accuracy: 0.7916 - val_loss: 0.3988 - val_accuracy: 0.8056\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.4040 - accuracy: 0.8056 - val_loss: 0.4136 - val_accuracy: 0.8056\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3973 - accuracy: 0.8066 - val_loss: 0.3562 - val_accuracy: 0.8056\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3833 - accuracy: 0.8036 - val_loss: 0.3866 - val_accuracy: 0.8056\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3757 - accuracy: 0.8052 - val_loss: 0.3483 - val_accuracy: 0.8076\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.3750 - accuracy: 0.8049 - val_loss: 0.3477 - val_accuracy: 0.8056\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3712 - accuracy: 0.8079 - val_loss: 0.3531 - val_accuracy: 0.8056\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3624 - accuracy: 0.8067 - val_loss: 0.3380 - val_accuracy: 0.8157\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3597 - accuracy: 0.8109 - val_loss: 0.3615 - val_accuracy: 0.8117\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3599 - accuracy: 0.8068 - val_loss: 0.3368 - val_accuracy: 0.8137\n",
      "---mixed dense list: [1024, 512, 256, 128, 64, 32], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.6670 - accuracy: 0.7895 - val_loss: 0.4009 - val_accuracy: 0.8056\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.4050 - accuracy: 0.8065 - val_loss: 0.3966 - val_accuracy: 0.8056\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3940 - accuracy: 0.8043 - val_loss: 0.3711 - val_accuracy: 0.8056\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3817 - accuracy: 0.8057 - val_loss: 0.3925 - val_accuracy: 0.8051\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3839 - accuracy: 0.8063 - val_loss: 0.3552 - val_accuracy: 0.8081\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.3702 - accuracy: 0.8055 - val_loss: 0.3644 - val_accuracy: 0.8056\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3746 - accuracy: 0.8080 - val_loss: 0.3535 - val_accuracy: 0.8056\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3649 - accuracy: 0.8063 - val_loss: 0.3535 - val_accuracy: 0.8132\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3646 - accuracy: 0.8082 - val_loss: 0.3464 - val_accuracy: 0.8096\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.3665 - accuracy: 0.8089 - val_loss: 0.3382 - val_accuracy: 0.8122\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_augm_dict = {}\n",
    "\n",
    "for mixed_dense_list in mixed_dense_lists:\n",
    "    for tabular_dense_list in tabular_dense_lists:\n",
    "        for activation_func in activation_list:\n",
    "        \n",
    "            print(\"---mixed dense list: \" + str(mixed_dense_list) + \", tabular dense list: \" + str(tabular_dense_list) + \", activation: \" + activation_func + \"---\")\n",
    "    \n",
    "            x_train_augm, tabular_augm, y_train_augm = aug_image(x_train_clean,\n",
    "                                                                 train_tabular_clean,\n",
    "                                                                 y_train_clean,\n",
    "                                                                 contrast_factor = 1,\n",
    "                                                                 delta = 0.1,\n",
    "                                                                 flip_flag = True)\n",
    "    \n",
    "            model = build_mixed_model(kernel_size = 3,\n",
    "                                      pool_size = 3,\n",
    "                                      tabular_shape = tabular_augm.shape[1],\n",
    "                                      tabular_activation_func = activation_func,\n",
    "                                      tabular_dense_list = tabular_dense_list,\n",
    "                                      mixed_dense_list = mixed_dense_list)\n",
    "    \n",
    "            history = model.fit(\n",
    "                [x_train_augm,\n",
    "                 tabular_augm],\n",
    "                y_train_augm,\n",
    "                validation_data = ([x_valid_augm,\n",
    "                                    valid_tabular_set],\n",
    "                                   y_valid),\n",
    "                epochs=10,  \n",
    "                batch_size=128\n",
    "            )\n",
    "\n",
    "            image_augm_dict[(len(mixed_dense_list), len(tabular_dense_list), activation_func)] = [history.history['accuracy'][-1], history.history['val_accuracy'][-1]]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4: fit models using oversample + image augmentation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---mixed dense list: [1024], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 1.7164 - accuracy: 0.7169 - val_loss: 0.5003 - val_accuracy: 0.7484\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4877 - accuracy: 0.7673 - val_loss: 0.4705 - val_accuracy: 0.7504\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4571 - accuracy: 0.7816 - val_loss: 0.4412 - val_accuracy: 0.7443\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 0.4345 - accuracy: 0.7944 - val_loss: 0.4278 - val_accuracy: 0.7519\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4322 - accuracy: 0.7946 - val_loss: 0.4579 - val_accuracy: 0.7323\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4227 - accuracy: 0.7980 - val_loss: 0.4240 - val_accuracy: 0.7594\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4106 - accuracy: 0.8046 - val_loss: 0.4445 - val_accuracy: 0.7524\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.3999 - accuracy: 0.8096 - val_loss: 0.4285 - val_accuracy: 0.7695\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.3859 - accuracy: 0.8189 - val_loss: 0.4278 - val_accuracy: 0.7820\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.3789 - accuracy: 0.8218 - val_loss: 0.4894 - val_accuracy: 0.7373\n",
      "---mixed dense list: [1024, 512], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.1189 - accuracy: 0.7147 - val_loss: 0.5062 - val_accuracy: 0.7454\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.4788 - accuracy: 0.7668 - val_loss: 0.4485 - val_accuracy: 0.7243\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4491 - accuracy: 0.7844 - val_loss: 0.4288 - val_accuracy: 0.7484\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 0.4371 - accuracy: 0.7904 - val_loss: 0.5565 - val_accuracy: 0.6705\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4199 - accuracy: 0.7995 - val_loss: 0.4490 - val_accuracy: 0.7323\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4035 - accuracy: 0.8069 - val_loss: 0.4282 - val_accuracy: 0.7514\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.3874 - accuracy: 0.8157 - val_loss: 0.4450 - val_accuracy: 0.7529\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.3717 - accuracy: 0.8253 - val_loss: 0.4085 - val_accuracy: 0.7815\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.3597 - accuracy: 0.8323 - val_loss: 0.4766 - val_accuracy: 0.7443\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 0.3795 - accuracy: 0.8268 - val_loss: 0.4496 - val_accuracy: 0.7549\n",
      "---mixed dense list: [1024, 512, 256], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.9529 - accuracy: 0.7085 - val_loss: 0.4872 - val_accuracy: 0.7559\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4870 - accuracy: 0.7652 - val_loss: 0.4503 - val_accuracy: 0.7293\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4563 - val_accuracy: 0.7273\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4469 - accuracy: 0.7839 - val_loss: 0.4795 - val_accuracy: 0.7152\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4399 - accuracy: 0.7899 - val_loss: 0.4824 - val_accuracy: 0.7167\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.4234 - accuracy: 0.7992 - val_loss: 0.4543 - val_accuracy: 0.7358\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4243 - accuracy: 0.7973 - val_loss: 0.4485 - val_accuracy: 0.7459\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4050 - accuracy: 0.8093 - val_loss: 0.3969 - val_accuracy: 0.7855\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.3901 - accuracy: 0.8157 - val_loss: 0.4600 - val_accuracy: 0.7388\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.3852 - accuracy: 0.8174 - val_loss: 0.4950 - val_accuracy: 0.7313\n",
      "---mixed dense list: [1024, 512, 256, 128], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7723 - accuracy: 0.7032 - val_loss: 0.4958 - val_accuracy: 0.7388\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.5114 - accuracy: 0.7542 - val_loss: 0.4481 - val_accuracy: 0.7544\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4771 - accuracy: 0.7703 - val_loss: 0.4709 - val_accuracy: 0.7353\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4569 - accuracy: 0.7790 - val_loss: 0.5053 - val_accuracy: 0.6781\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.5368 - accuracy: 0.7362 - val_loss: 0.6485 - val_accuracy: 0.5726\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4657 - accuracy: 0.7735 - val_loss: 0.4686 - val_accuracy: 0.7192\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4447 - accuracy: 0.7873 - val_loss: 0.4569 - val_accuracy: 0.7228\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4408 - accuracy: 0.7894 - val_loss: 0.4103 - val_accuracy: 0.7599\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4187 - accuracy: 0.7990 - val_loss: 0.4341 - val_accuracy: 0.7639\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4020 - accuracy: 0.8096 - val_loss: 0.5158 - val_accuracy: 0.7263\n",
      "---mixed dense list: [1024, 512, 256, 128, 64], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.8476 - accuracy: 0.7040 - val_loss: 0.5142 - val_accuracy: 0.7353\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.5241 - accuracy: 0.7454 - val_loss: 0.4284 - val_accuracy: 0.7685\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4892 - accuracy: 0.7633 - val_loss: 0.4781 - val_accuracy: 0.7298\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4651 - accuracy: 0.7749 - val_loss: 0.4532 - val_accuracy: 0.7152\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4481 - accuracy: 0.7855 - val_loss: 0.5530 - val_accuracy: 0.6735\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.4337 - accuracy: 0.7924 - val_loss: 0.4183 - val_accuracy: 0.7459\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4206 - accuracy: 0.8007 - val_loss: 0.4201 - val_accuracy: 0.7730\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4143 - accuracy: 0.8016 - val_loss: 0.4072 - val_accuracy: 0.7745\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4037 - accuracy: 0.8109 - val_loss: 0.4320 - val_accuracy: 0.7594\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.3922 - accuracy: 0.8143 - val_loss: 0.4908 - val_accuracy: 0.7212\n",
      "---mixed dense list: [1024, 512, 256, 128, 64, 32], tabular dense list: [32, 64, 64], activation: tanh---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.7203 - accuracy: 0.6941 - val_loss: 0.5177 - val_accuracy: 0.7318\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.5121 - accuracy: 0.7483 - val_loss: 0.4218 - val_accuracy: 0.7649\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.4768 - accuracy: 0.7718 - val_loss: 0.4712 - val_accuracy: 0.7072\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4538 - accuracy: 0.7841 - val_loss: 0.5600 - val_accuracy: 0.6409\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4483 - accuracy: 0.7817 - val_loss: 0.4767 - val_accuracy: 0.7117\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.4372 - accuracy: 0.7897 - val_loss: 0.4189 - val_accuracy: 0.7408\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.4312 - accuracy: 0.7950 - val_loss: 0.4754 - val_accuracy: 0.7107\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.4431 - val_accuracy: 0.7644\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.3967 - accuracy: 0.8155 - val_loss: 0.4336 - val_accuracy: 0.7534\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.3859 - accuracy: 0.8178 - val_loss: 0.5715 - val_accuracy: 0.6941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_augm_over_dict = {}\n",
    "\n",
    "for mixed_dense_list in mixed_dense_lists:\n",
    "    for tabular_dense_list in tabular_dense_lists:\n",
    "        for activation_func in activation_list:\n",
    "        \n",
    "            print(\"---mixed dense list: \" + str(mixed_dense_list) + \", tabular dense list: \" + str(tabular_dense_list) + \", activation: \" + activation_func + \"---\")\n",
    "\n",
    "            x_train_oversample_augm, tabular_oversample_augm, y_train_oversample_augm = aug_image(x_train_oversample,\n",
    "                                                                                                  train_tabular_oversample,\n",
    "                                                                                                  y_train_oversample,\n",
    "                                                                                                  contrast_factor = 1,\n",
    "                                                                                                  delta = 0.1,\n",
    "                                                                                                  flip_flag = True)\n",
    "    \n",
    "            model = build_mixed_model(kernel_size = 3,\n",
    "                                      pool_size = 3,\n",
    "                                      tabular_shape = tabular_oversample_augm.shape[1],\n",
    "                                      tabular_activation_func = activation_func,\n",
    "                                      tabular_dense_list = tabular_dense_list,\n",
    "                                      mixed_dense_list = mixed_dense_list)\n",
    "    \n",
    "            history = model.fit(\n",
    "                [x_train_oversample_augm,\n",
    "                 tabular_oversample_augm],\n",
    "                y_train_oversample_augm,\n",
    "                validation_data = ([x_valid_augm,\n",
    "                                    valid_tabular_set],\n",
    "                                   y_valid),\n",
    "                epochs=10,  \n",
    "                batch_size=128\n",
    "            )\n",
    "\n",
    "            image_augm_over_dict[(len(mixed_dense_list), len(tabular_dense_list), activation_func)] = [history.history['accuracy'][-1], history.history['val_accuracy'][-1]]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Output Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "clean_table = []\n",
    "\n",
    "for key in clean_dict:\n",
    "    clean_table.append([key[0], key[1], key[2], clean_dict[key][0], clean_dict[key][1]])\n",
    "\n",
    "with open('clean_mixed_binary.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(clean_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oversample_table = []\n",
    "\n",
    "for key in oversample_dict:\n",
    "    oversample_table.append([key[0], key[1], key[2], oversample_dict[key][0], oversample_dict[key][1]])\n",
    "\n",
    "with open('oversample_mixed_binary.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(oversample_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_augm_table = []\n",
    "\n",
    "for key in image_augm_dict:\n",
    "    image_augm_table.append([key[0], key[1], key[2], image_augm_dict[key][0], image_augm_dict[key][1]])\n",
    "\n",
    "with open('image_augm_mixed_binary.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(image_augm_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_augm_over_table = []\n",
    "\n",
    "for key in image_augm_over_dict:\n",
    "    image_augm_over_table.append([key[0], key[1], key[2], image_augm_over_dict[key][0], image_augm_over_dict[key][1]])\n",
    "\n",
    "with open('image_augm_over_mixed_binary.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(image_augm_over_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
